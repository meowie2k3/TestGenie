\section{Conclusion}
% gia tri su dung - implication

This thesis has presented Test Genie, a novel system for automated test generation in Flutter applications that addresses fundamental challenges in software testing through an innovative block-based analysis approach. By developing a solution that intelligently analyzes business logic from source code and generates human-readable, executable test cases, this research makes several significant contributions to both academic understanding and practical application in software engineering.

The central innovation of Test Genie—its block-based decomposition approach—represents a paradigm shift in how AI-driven test generation can be conceptualized. By breaking down complex codebases into semantically meaningful units, the system achieves a balance between analytical depth and computational efficiency that previous approaches have struggled to attain. This decomposition strategy effectively mitigates the source code bias problem that has plagued automated testing tools, creating tests that validate business requirements rather than merely confirming implementation details.

Empirical evaluation confirms that Test Genie achieves impressive performance characteristics, with algorithmic complexity that scales linearly with code size ($O(LOC)$) and test generation accuracy approaching 90\% after error correction. Human evaluations particularly highlighted the readability and relevance of generated tests, addressing a critical limitation of traditional automated testing approaches. These results validate the practical utility of the system in real-world development scenarios, where it demonstrated a 62\% reduction in time spent writing tests compared to manual authoring.

Beyond its immediate practical applications, this research carries broader implications for software engineering practices. The human-in-the-loop design philosophy embedded throughout Test Genie demonstrates how AI and human expertise can be synergistically combined, leveraging the strengths of each while mitigating their respective weaknesses. This collaborative approach represents a promising direction for AI-augmented software engineering tools that enhance developer productivity without diminishing human agency or understanding.

In addressing the challenge of automated test generation for the Flutter framework, this thesis makes a meaningful contribution to the growing field of mobile and cross-platform application development. As these frameworks continue to evolve and gain popularity, the need for efficient testing methodologies becomes increasingly acute. Test Genie establishes a foundation upon which more sophisticated testing approaches can be built, potentially influencing the design of both testing tools and frameworks themselves.

From an academic perspective, this research advances understanding of how large language models can be effectively applied to specialized software engineering tasks. The retrieval-augmented generation approach employed in Test Genie demonstrates how domain-specific knowledge can be incorporated into AI systems to improve accuracy and relevance in technical contexts. This contributes to the broader discourse on adapting general-purpose AI technologies to specialized domains.

The interdisciplinary nature of this work—bridging software engineering, artificial intelligence, and human-computer interaction—highlights the increasingly blurred boundaries between these fields. As software systems grow more complex and AI capabilities more sophisticated, such interdisciplinary approaches become not merely beneficial but essential. Test Genie exemplifies how insights from multiple disciplines can be integrated to create tools that address complex challenges in ways that single-discipline approaches cannot.

In conclusion, Test Genie represents a significant advancement in automated test generation, offering both immediate practical value through enhanced testing efficiency and broader implications for how AI can be thoughtfully integrated into software development workflows. By balancing technical sophistication with usability, and automation with human oversight, this system establishes a model for AI-augmented development tools that enhance rather than replace human capabilities. As software continues to pervade every aspect of modern life, such tools will play an increasingly vital role in ensuring software quality, reliability, and security.

\section{Future Work}

While Test Genie has demonstrated significant advances in automated test generation for Flutter applications, several promising research directions remain to be explored. These potential extensions would address current limitations and further enhance the system's capabilities.

First, expanding framework support beyond Flutter represents a natural evolution of this research. The block-based decomposition approach developed in this thesis could be adapted to other mobile and web frameworks such as React Native, Angular, or SwiftUI. This expansion would require developing framework-specific analyzers and test generators, but the core architectural concepts should transfer effectively. Comparative studies across different frameworks might also yield insights into architectural patterns that are particularly amenable to automated testing.

Second, enhancing the system's handling of complex state management represents a critical area for improvement. As noted in the evaluation, Test Genie's performance decreased when dealing with sophisticated state management patterns like BLoC or Redux. Future research could explore specialized analysis techniques for these patterns, potentially incorporating static flow analysis to better understand state transformations and dependencies. This would address one of the most challenging aspects of modern application testing.

Third, the current test validation approach focuses primarily on syntactic correctness and runnability. A valuable extension would be developing techniques to evaluate test quality and coverage more comprehensively. This might include measuring assertion quality, behavior coverage (rather than just code coverage), and alignment with business requirements. Such advancements would help ensure that generated tests provide meaningful validation rather than superficial verification.

Fourth, investigating the potential for reinforcement learning with human feedback (RLHF) could significantly improve prediction accuracy. By systematically collecting and incorporating user corrections of block predictions, the system could continuously refine its understanding of business logic patterns. This approach would leverage the human-in-the-loop architecture already present in Test Genie while reducing the need for manual intervention over time.

Fifth, as mobile applications increasingly leverage platform-specific features, improving the generation of tests for platform channels and native code integration represents an important challenge. Future work could explore techniques for analyzing cross-language interfaces and generating appropriate mocks and test harnesses for platform-specific components.

Finally, integrating Test Genie with continuous integration and deployment pipelines would enhance its practical utility in professional development environments. Research into effective integration patterns, incremental test updating based on code changes, and optimization for performance in CI environments would make the system more applicable to real-world development workflows.

These research directions would build upon the foundation established in this thesis, addressing existing limitations while extending the applicability and effectiveness of AI-driven test generation systems. As software continues to grow in complexity and criticality, such advancements will become increasingly valuable for ensuring quality, reliability, and security.